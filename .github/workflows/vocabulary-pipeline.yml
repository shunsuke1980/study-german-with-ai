name: German Vocabulary Pipeline

on:
  push:
    paths:
      - 'data/words/*.txt'
    branches:
      - main
  workflow_dispatch:

jobs:
  generate-vocabulary-content:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    outputs:
      content_generated: ${{ steps.check_content.outputs.generated }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install anthropic azure-cognitiveservices-speech watchdog

    - name: Generate vocabulary content and audio
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        AZURE_SPEECH_KEY: ${{ secrets.AZURE_SPEECH_KEY }}
        AZURE_SPEECH_REGION: ${{ secrets.AZURE_SPEECH_REGION }}
      run: |
        python generate_vocab_content.py

    - name: Check if content was generated
      id: check_content
      run: |
        git add _posts/ assets/audio/ data/ssml/
        if git diff --staged --quiet; then
          echo "No new content generated"
          echo "generated=false" >> $GITHUB_OUTPUT
        else
          echo "New vocabulary content detected"
          echo "generated=true" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push new content
      if: steps.check_content.outputs.generated == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Vocabulary Content Generator"

        # Pull latest changes first to avoid conflicts
        git pull --rebase origin main || true

        # Get episode number from latest generated file
        EPISODE_NUM=$(ls -1 _posts/*-german-vocab-episode-*.md 2>/dev/null | tail -1 | grep -o 'episode-[0-9]*' | grep -o '[0-9]*' || echo "1")
        
        COMMIT_MSG="Generate German vocabulary episode ${EPISODE_NUM} with audio $(date +%Y-%m-%d)"
        git commit -m "$COMMIT_MSG"

        # Try to push, with retry logic
        for i in {1..3}; do
          if git push; then
            echo "Push successful on attempt $i"
            break
          else
            echo "Push failed on attempt $i, pulling and retrying..."
            git pull --rebase origin main || true
            sleep 2
          fi
        done

  generate-audio-from-ssml:
    needs: generate-vocabulary-content
    if: needs.generate-vocabulary-content.outputs.content_generated == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    outputs:
      audio_generated: ${{ steps.check_audio.outputs.generated }}

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Pull latest changes including SSML files
      run: |
        echo "Pulling latest changes from main"
        git pull origin main || true
        echo "Current HEAD commit:"
        git log -1 --oneline
        echo "Checking for SSML files:"
        ls -la data/ssml/ || echo "No data/ssml directory found"

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    - name: Install Python dependencies
      run: |
        pip install azure-cognitiveservices-speech pydub

    - name: Generate audio files from SSML
      env:
        AZURE_SPEECH_KEY: ${{ secrets.AZURE_SPEECH_KEY }}
        AZURE_SPEECH_REGION: ${{ secrets.AZURE_SPEECH_REGION }}
      run: |
        python << 'EOF'
        import os
        import re
        import io
        from pathlib import Path
        import azure.cognitiveservices.speech as speechsdk
        from pydub import AudioSegment

        def split_ssml_content(ssml_content, max_bytes=50000):
            """Split SSML content into chunks under the byte limit"""
            # Extract content between <speak> tags
            speak_match = re.search(r'<speak[^>]*>(.*)</speak>', ssml_content, re.DOTALL)
            if not speak_match:
                print("‚ùå No <speak> tags found in SSML")
                return []
            
            inner_content = speak_match.group(1).strip()
            
            # Split by major breaks (2+ seconds) to create logical chunks
            major_breaks = re.split(r'<break\s+time="[2-9]s"\s*/>', inner_content)
            
            chunks = []
            current_chunk = ""
            
            for segment in major_breaks:
                # Test if adding this segment would exceed the limit
                test_chunk = f'<speak>{current_chunk}{segment}</speak>'
                
                if len(test_chunk.encode('utf-8')) <= max_bytes:
                    # Add to current chunk
                    if current_chunk:
                        current_chunk += '<break time="2s"/>'
                    current_chunk += segment
                else:
                    # Start new chunk
                    if current_chunk:
                        chunks.append(f'<speak>{current_chunk}</speak>')
                    current_chunk = segment
                    
                    # If single segment is too large, split it further
                    if len(f'<speak>{current_chunk}</speak>'.encode('utf-8')) > max_bytes:
                        # Split by smaller breaks (1s)
                        small_segments = re.split(r'<break\s+time="1s"\s*/>', current_chunk)
                        current_chunk = ""
                        
                        for small_seg in small_segments:
                            test_small = f'<speak>{current_chunk}{small_seg}</speak>'
                            if len(test_small.encode('utf-8')) <= max_bytes:
                                if current_chunk:
                                    current_chunk += '<break time="1s"/>'
                                current_chunk += small_seg
                            else:
                                if current_chunk:
                                    chunks.append(f'<speak>{current_chunk}</speak>')
                                current_chunk = small_seg
            
            # Add final chunk
            if current_chunk:
                chunks.append(f'<speak>{current_chunk}</speak>')
            
            return chunks

        def generate_audio_from_ssml():
            """Generate MP3 audio files from SSML files"""
            print("üéµ Generating audio files from SSML...")
            
            # Check for Azure credentials
            if 'AZURE_SPEECH_KEY' not in os.environ or 'AZURE_SPEECH_REGION' not in os.environ:
                print("‚ùå Azure Speech credentials not found")
                return False
            
            # Install pydub if not available
            try:
                import pydub
            except ImportError:
                print("üì¶ Installing pydub...")
                os.system("pip install pydub")
                import pydub
            
            # Configure Azure Speech Service
            speech_config = speechsdk.SpeechConfig(
                subscription=os.environ['AZURE_SPEECH_KEY'],
                region=os.environ['AZURE_SPEECH_REGION']
            )
            
            # Set the voice to Florian Multilingual
            speech_config.speech_synthesis_voice_name = "de-DE-FlorianMultilingualNeural"
            
            # Set output format to MP3
            speech_config.set_speech_synthesis_output_format(
                speechsdk.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3
            )
            
            # Find SSML files
            ssml_dir = Path("data/ssml")
            if not ssml_dir.exists():
                print("‚ùå No data/ssml directory found")
                return False
            
            ssml_files = list(ssml_dir.glob("episode-*-ssml.xml"))
            if not ssml_files:
                print("‚ÑπÔ∏è  No SSML files found")
                return False
            
            print(f"üìÑ Found {len(ssml_files)} SSML files")
            
            # Ensure audio directory exists
            audio_dir = Path("assets/audio")
            audio_dir.mkdir(parents=True, exist_ok=True)
            
            audio_generated = False
            
            for ssml_file in ssml_files:
                # Extract episode number from filename
                episode_match = re.search(r'episode-(\d+)-ssml\.xml$', ssml_file.name)
                if not episode_match:
                    print(f"‚ö†Ô∏è  Skipping {ssml_file.name} - invalid filename format")
                    continue
                
                episode_num = episode_match.group(1)
                audio_file = audio_dir / f"episode-{episode_num}.mp3"
                
                # Skip if audio file already exists
                if audio_file.exists():
                    print(f"‚è≠Ô∏è  Audio file already exists: {audio_file.name}")
                    continue
                
                print(f"üîÑ Processing {ssml_file.name} -> {audio_file.name}")
                
                try:
                    # Read SSML content
                    with open(ssml_file, 'r', encoding='utf-8') as f:
                        ssml_content = f.read()
                    
                    # Clean up SSML (remove XML declaration if present)
                    if ssml_content.startswith('<?xml'):
                        lines = ssml_content.split('\n')
                        ssml_content = '\n'.join(lines[1:])
                    
                    # Remove extra whitespace and formatting
                    ssml_content = re.sub(r'\n\s*', ' ', ssml_content)
                    ssml_content = re.sub(r'\s+', ' ', ssml_content).strip()
                    
                    content_bytes = len(ssml_content.encode('utf-8'))
                    print(f"üìù SSML content length: {content_bytes} bytes")
                    
                    # Azure Speech Services has a much higher limit (~50KB), but we'll still check
                    if content_bytes > 45000:  # Leave some buffer under 50KB
                        print(f"‚ö†Ô∏è  Content too large ({content_bytes} bytes), splitting into chunks...")
                        ssml_chunks = split_ssml_content(ssml_content)
                        print(f"üìÇ Split into {len(ssml_chunks)} chunks")
                        
                        # Generate audio for each chunk
                        audio_segments = []
                        
                        for i, chunk in enumerate(ssml_chunks):
                            chunk_bytes = len(chunk.encode('utf-8'))
                            print(f"üîä Processing chunk {i+1}/{len(ssml_chunks)} ({chunk_bytes} bytes)...")
                            
                            # Create temporary file for this chunk
                            chunk_file = audio_dir / f"temp_chunk_{i}.mp3"
                            
                            # Create audio config for this chunk
                            chunk_audio_config = speechsdk.audio.AudioOutputConfig(filename=str(chunk_file))
                            chunk_synthesizer = speechsdk.SpeechSynthesizer(
                                speech_config=speech_config,
                                audio_config=chunk_audio_config
                            )
                            
                            # Generate audio for this chunk
                            result = chunk_synthesizer.speak_ssml_async(chunk).get()
                            
                            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                                # Load audio chunk into pydub
                                audio_segment = AudioSegment.from_mp3(str(chunk_file))
                                audio_segments.append(audio_segment)
                                
                                # Clean up temporary file
                                chunk_file.unlink()
                                
                                print(f"‚úÖ Chunk {i+1} generated")
                            else:
                                print(f"‚ùå Failed to generate chunk {i+1}")
                                if result.reason == speechsdk.ResultReason.Canceled:
                                    details = result.cancellation_details
                                    print(f"‚ùå Cancellation reason: {details.reason}")
                                    if details.reason == speechsdk.CancellationReason.Error:
                                        print(f"‚ùå Error details: {details.error_details}")
                        
                        # Concatenate all audio segments
                        if audio_segments:
                            print("üîó Concatenating audio chunks...")
                            final_audio = AudioSegment.empty()
                            for segment in audio_segments:
                                final_audio += segment
                            
                            # Export final audio
                            final_audio.export(str(audio_file), format="mp3")
                        else:
                            print("‚ùå No audio chunks were generated successfully")
                            continue
                        
                    else:
                        # Content fits in single request
                        print(f"üîä Generating audio with Azure Speech Services (single request)...")
                        
                        # Create audio config for direct file output
                        file_audio_config = speechsdk.audio.AudioOutputConfig(filename=str(audio_file))
                        synthesizer = speechsdk.SpeechSynthesizer(
                            speech_config=speech_config,
                            audio_config=file_audio_config
                        )
                        
                        # Generate audio
                        result = synthesizer.speak_ssml_async(ssml_content).get()
                        
                        if result.reason != speechsdk.ResultReason.SynthesizingAudioCompleted:
                            print(f"‚ùå Speech synthesis failed")
                            if result.reason == speechsdk.ResultReason.Canceled:
                                details = result.cancellation_details
                                print(f"‚ùå Cancellation reason: {details.reason}")
                                if details.reason == speechsdk.CancellationReason.Error:
                                    print(f"‚ùå Error details: {details.error_details}")
                            continue
                    
                    # Verify file was created and has content
                    if audio_file.exists() and audio_file.stat().st_size > 0:
                        file_size = audio_file.stat().st_size
                        print(f"‚úÖ Audio generated: {audio_file.name} ({file_size:,} bytes)")
                        audio_generated = True
                    else:
                        print(f"‚ùå Failed to create audio file: {audio_file.name}")
                    
                except Exception as e:
                    print(f"‚ùå Error generating audio for {ssml_file.name}: {e}")
                    # Print more details for debugging
                    import traceback
                    print(f"üîç Full error: {traceback.format_exc()}")
            
            if audio_generated:
                print("‚úÖ Audio generation completed successfully")
                return True
            else:
                print("‚ÑπÔ∏è  No new audio files generated")
                return False

        # Run audio generation
        success = generate_audio_from_ssml()
        
        # Create flag file to indicate success
        if success:
            with open("audio_generated_flag.txt", "w") as f:
                f.write("true")
        EOF

    - name: Check if audio was generated
      id: check_audio
      run: |
        if [ -f "audio_generated_flag.txt" ]; then
          echo "Audio files were generated from SSML"
          echo "generated=true" >> $GITHUB_OUTPUT
          rm -f audio_generated_flag.txt
        else
          echo "No audio files generated from SSML"
          echo "generated=false" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push audio files
      if: steps.check_audio.outputs.generated == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Azure Speech Audio Generator"

        # Pull latest changes first
        git pull --rebase origin main || true

        # Add audio files
        git add assets/audio/*.mp3 || true

        # Only commit if there are changes
        if ! git diff --staged --quiet; then
          git commit -m "Generate audio files from SSML using Azure Speech Services [skip ci]"

          # Try to push with retry logic
          for i in {1..3}; do
            if git push; then
              echo "Audio push successful on attempt $i"
              break
            else
              echo "Audio push failed on attempt $i, pulling and retrying..."
              git pull --rebase origin main || true
              sleep 2
            fi
          done
        else
          echo "No new audio files to commit"
        fi

  update-podcast-rss:
    needs: [generate-vocabulary-content, generate-audio-from-ssml]
    if: needs.generate-vocabulary-content.outputs.content_generated == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Pull latest changes including vocabulary content
      run: |
        echo "Pulling latest changes from main"
        git pull origin main || true
        echo "Current HEAD commit:"
        git log -1 --oneline
        echo "Checking for vocabulary audio files:"
        ls -la assets/audio/ || echo "No assets/audio directory found"

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Generate Updated Podcast RSS Feed
      run: |
        python << 'EOF'
        import os
        import re
        import xml.etree.ElementTree as ET
        from datetime import datetime, timezone
        from pathlib import Path
        import email.utils

        def get_file_size(file_path):
            """Get file size in bytes"""
            try:
                return os.path.getsize(file_path)
            except OSError:
                return 0

        def estimate_duration(file_size_bytes):
            """Estimate MP3 duration from file size (assuming 128kbps)"""
            duration_seconds = max(1, file_size_bytes // 16000)
            hours = duration_seconds // 3600
            minutes = (duration_seconds % 3600) // 60
            seconds = duration_seconds % 60
            
            if hours > 0:
                return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
            else:
                return f"{minutes:02d}:{seconds:02d}"

        def parse_vocabulary_post(post_file):
            """Extract metadata from vocabulary blog post"""
            title = None
            episode_number = None
            
            try:
                with open(post_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if content.startswith('---'):
                    end_marker = content.find('---', 3)
                    if end_marker != -1:
                        frontmatter = content[3:end_marker]
                        
                        for line in frontmatter.split('\n'):
                            line = line.strip()
                            if line.startswith('title:'):
                                title = line.split('title:', 1)[1].strip().strip('"\'')
                            elif line.startswith('episode_number:'):
                                episode_number = line.split('episode_number:', 1)[1].strip()
                                
            except Exception as e:
                print(f"Error parsing post {post_file}: {e}")
            
            return title, episode_number

        def create_vocabulary_podcast_rss():
            """Generate podcast RSS feed including vocabulary episodes"""
            print("üéôÔ∏è Generating vocabulary podcast RSS feed...")
            
            base_url = "https://www.study-german.info"
            email_address = "24.madding_cuts@icloud.com"
            
            # Create RSS root element
            rss = ET.Element('rss')
            rss.set('version', '2.0')
            rss.set('xmlns:itunes', 'http://www.itunes.com/dtds/podcast-1.0.dtd')
            rss.set('xmlns:content', 'http://purl.org/rss/1.0/modules/content/')
            
            channel = ET.SubElement(rss, 'channel')
            
            # Podcast metadata
            ET.SubElement(channel, 'title').text = "Study German with AI - Vocabulary Learning"
            ET.SubElement(channel, 'description').text = "Daily German vocabulary learning with AI-generated content, etymology, and pronunciation practice"
            ET.SubElement(channel, 'link').text = base_url
            ET.SubElement(channel, 'language').text = "de-DE"
            ET.SubElement(channel, 'copyright').text = f"¬© {datetime.now().year} AI German Learning System"
            ET.SubElement(channel, 'managingEditor').text = f"{email_address} (AI German Learning System)"
            ET.SubElement(channel, 'webMaster').text = f"{email_address} (AI German Learning System)"
            ET.SubElement(channel, 'pubDate').text = email.utils.formatdate(datetime.now().timestamp())
            ET.SubElement(channel, 'lastBuildDate').text = email.utils.formatdate(datetime.now().timestamp())
            ET.SubElement(channel, 'generator').text = "AI German Vocabulary Learning System"
            
            # iTunes-specific tags
            ET.SubElement(channel, 'itunes:author').text = "AI German Learning System"
            ET.SubElement(channel, 'itunes:summary').text = "Learn German vocabulary with AI-generated content featuring etymology, memory techniques, and pronunciation practice"
            
            # iTunes owner
            owner = ET.SubElement(channel, 'itunes:owner')
            ET.SubElement(owner, 'itunes:name').text = "AI German Learning System"
            ET.SubElement(owner, 'itunes:email').text = email_address
            
            ET.SubElement(channel, 'itunes:explicit').text = "false"
            ET.SubElement(channel, 'itunes:type').text = "episodic"
            
            # Category
            category = ET.SubElement(channel, 'itunes:category')
            category.set('text', 'Education')
            subcategory = ET.SubElement(category, 'itunes:category')
            subcategory.set('text', 'Language Learning')
            
            # Image/artwork
            itunes_image = ET.SubElement(channel, 'itunes:image')
            itunes_image.set('href', f"{base_url}/assets/images/podcast.jpg")
            
            # Find all vocabulary episode files
            posts_dir = Path('_posts')
            episodes = []
            
            if posts_dir.exists():
                # Get both regular posts and vocabulary episodes
                all_posts = list(posts_dir.glob('*.md'))
                
                for post_file in all_posts:
                    # Check if it's a vocabulary episode
                    if 'german-vocab-episode' in post_file.name:
                        # Extract episode number and date
                        date_match = re.match(r'^(\d{4}-\d{2}-\d{2})', post_file.name)
                        episode_match = re.search(r'episode-(\d+)', post_file.name)
                        
                        if date_match and episode_match:
                            date_str = date_match.group(1)
                            episode_num = int(episode_match.group(1))
                            
                            try:
                                episode_date = datetime.strptime(date_str, '%Y-%m-%d')
                            except ValueError:
                                continue
                            
                            # Parse post metadata
                            title, _ = parse_vocabulary_post(post_file)
                            
                            # Look for corresponding audio files (single or multi-part)
                            audio_files = []
                            single_audio = Path(f'assets/audio/episode-{episode_num}.mp3')
                            
                            if single_audio.exists():
                                # Single file episode
                                audio_files = [single_audio]
                            else:
                                # Check for multi-part episodes
                                audio_dir = Path('assets/audio')
                                if audio_dir.exists():
                                    # Find all parts for this episode
                                    part_files = list(audio_dir.glob(f'episode-{episode_num}-part-*.mp3'))
                                    quiz_files = list(audio_dir.glob(f'episode-{episode_num}-quiz.mp3'))
                                    
                                    # Sort part files by part number
                                    part_files.sort(key=lambda x: int(re.search(r'part-(\d+)', x.name).group(1)) if re.search(r'part-(\d+)', x.name) else 0)
                                    
                                    audio_files = part_files + quiz_files
                            
                            if audio_files:
                                # Create episode entry for each audio file
                                for i, audio_file in enumerate(audio_files):
                                    file_size = get_file_size(audio_file)
                                    duration = estimate_duration(file_size)
                                    
                                    # Determine episode title and type
                                    filename = audio_file.name
                                    if 'quiz' in filename:
                                        episode_title = f"{title or f'German Vocabulary Episode {episode_num}'} - Quiz"
                                        episode_description = f"Quiz section for Episode {episode_num} - Test your knowledge"
                                        episode_type = 'bonus'
                                    elif 'part' in filename:
                                        part_match = re.search(r'part-(\d+)', filename)
                                        part_num = part_match.group(1) if part_match else '1'
                                        episode_title = f"{title or f'German Vocabulary Episode {episode_num}'} - Part {part_num}"
                                        episode_description = f"Part {part_num} of Episode {episode_num} featuring German vocabulary with etymology and pronunciation"
                                        episode_type = 'full'
                                    else:
                                        episode_title = title or f"German Vocabulary Episode {episode_num}"
                                        episode_description = f"Learn German vocabulary with Episode {episode_num} featuring etymology, memory techniques, and pronunciation practice."
                                        episode_type = 'full'
                                    
                                    episode_data = {
                                        'date': episode_date,
                                        'title': episode_title,
                                        'episode_number': episode_num,
                                        'audio_url': f"{base_url}/assets/audio/{filename}",
                                        'file_size': file_size,
                                        'duration': duration,
                                        'description': episode_description,
                                        'episode_type': episode_type
                                    }
                                    
                                    episodes.append(episode_data)
                                    print(f"‚úÖ Found vocabulary episode: {episode_num} - {episode_title}")
                    
                    else:
                        # Handle regular German learning posts
                        date_match = re.match(r'^(\d{4}-\d{2}-\d{2})', post_file.name)
                        if date_match and not post_file.name.endswith('-jp.md'):
                            date_str = date_match.group(1)
                            
                            try:
                                episode_date = datetime.strptime(date_str, '%Y-%m-%d')
                            except ValueError:
                                continue
                            
                            # Look for corresponding audio file
                            audio_file = Path(f'assets/audio/{post_file.stem}.mp3')
                            if audio_file.exists():
                                # Parse post metadata
                                title, _ = parse_vocabulary_post(post_file)
                                
                                file_size = get_file_size(audio_file)
                                duration = estimate_duration(file_size)
                                
                                episode_data = {
                                    'date': episode_date,
                                    'title': title or f"German Learning - {date_str}",
                                    'episode_number': None,  # Regular posts don't have episode numbers
                                    'audio_url': f"{base_url}/assets/audio/{post_file.stem}.mp3",
                                    'file_size': file_size,
                                    'duration': duration,
                                    'description': f"German learning content for {date_str} with comprehensive vocabulary and grammar."
                                }
                                
                                episodes.append(episode_data)
            
            # Sort episodes by date (newest first)
            episodes.sort(key=lambda x: x['date'], reverse=True)
            
            print(f"üìö Found {len(episodes)} total episodes")
            
            # Generate episode items
            for episode in episodes:
                item = ET.SubElement(channel, 'item')
                
                # Basic episode info
                ET.SubElement(item, 'title').text = episode['title']
                ET.SubElement(item, 'description').text = episode['description']
                ET.SubElement(item, 'link').text = f"{base_url}/"
                
                # GUID
                if episode['episode_number']:
                    guid = f"{base_url}/vocabulary/episode-{episode['episode_number']}"
                else:
                    guid = f"{base_url}/episodes/{episode['date'].strftime('%Y-%m-%d')}"
                ET.SubElement(item, 'guid').text = guid
                
                # Publication date
                pub_date = episode['date'].replace(hour=9, minute=0, second=0, tzinfo=timezone.utc)
                ET.SubElement(item, 'pubDate').text = email.utils.formatdate(pub_date.timestamp())
                
                # Audio enclosure
                enclosure = ET.SubElement(item, 'enclosure')
                enclosure.set('url', episode['audio_url'])
                enclosure.set('length', str(episode['file_size']))
                enclosure.set('type', 'audio/mpeg')
                
                # iTunes-specific episode tags
                ET.SubElement(item, 'itunes:title').text = episode['title']
                ET.SubElement(item, 'itunes:summary').text = episode['description']
                ET.SubElement(item, 'itunes:duration').text = episode['duration']
                
                if episode['episode_number']:
                    ET.SubElement(item, 'itunes:episode').text = str(episode['episode_number'])
                    
                episode_type = episode.get('episode_type', 'full')
                ET.SubElement(item, 'itunes:episodeType').text = episode_type
                ET.SubElement(item, 'itunes:explicit').text = "false"
            
            # Format and write RSS file
            def indent(elem, level=0):
                i = "\n" + level * "  "
                if len(elem):
                    if not elem.text or not elem.text.strip():
                        elem.text = i + "  "
                    if not elem.tail or not elem.tail.strip():
                        elem.tail = i
                    for child in elem:
                        indent(child, level + 1)
                    if not child.tail or not child.tail.strip():
                        child.tail = i
                else:
                    if level and (not elem.tail or not elem.tail.strip()):
                        elem.tail = i
            
            indent(rss)
            tree = ET.ElementTree(rss)
            
            # Write with XML declaration
            with open('podcast.rss', 'wb') as f:
                f.write(b'<?xml version="1.0" encoding="UTF-8"?>\n')
                tree.write(f, encoding='utf-8', xml_declaration=False)
            
            print(f"‚úÖ Generated vocabulary podcast RSS with {len(episodes)} episodes")
            
            # Verify the file was created
            if Path('podcast.rss').exists():
                file_size = Path('podcast.rss').stat().st_size
                print(f"üìÑ RSS file size: {file_size} bytes")
            else:
                print("‚ùå Failed to create podcast.rss file")

        # Run the RSS generation
        create_vocabulary_podcast_rss()
        EOF

    - name: Commit and push RSS feed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "Vocabulary Podcast RSS Generator"

        # Pull latest changes first
        git pull --rebase origin main || true

        # Only add and commit if the file exists
        if [ -f "podcast.rss" ]; then
          git add podcast.rss
          if git diff --staged --quiet; then
            echo "No changes to RSS feed"
          else
            git commit -m "Update podcast RSS feed with vocabulary episodes"
            
            # Try to push with retry logic
            for i in {1..3}; do
              if git push; then
                echo "RSS push successful on attempt $i"
                break
              else
                echo "RSS push failed on attempt $i, pulling and retrying..."
                git pull --rebase origin main || true
                sleep 2
              fi
            done
          fi
        else
          echo "podcast.rss file not found, skipping commit"
        fi

    - name: Display feed info
      run: |
        if [ -f "podcast.rss" ]; then
          echo "‚úÖ Vocabulary podcast RSS feed generated successfully"
          echo "üìä RSS file size: $(stat -c%s podcast.rss 2>/dev/null || wc -c < podcast.rss) bytes"
          echo "üîó RSS feed URL: https://www.study-german.info/podcast.rss"
          echo "üì± Add this URL to your podcast app!"
          
          # Count vocabulary episodes
          VOCAB_COUNT=$(grep -c "german-vocab-episode" podcast.rss || echo "0")
          echo "üìö Vocabulary episodes in feed: $VOCAB_COUNT"
        else
          echo "‚ùå Failed to generate RSS feed"
        fi